# 📊 데이터셋 증배기 (Dataset Multiplier)

## 🎯 빠른 시작 명령어

```bash
# 1. 저장 공간 확인
python scripts/generate_datasets.py check_storage_space

# 2. 빠른 테스트 (2배 증강)
python scripts/generate_datasets.py generate_quick_test --multiplier=2

# 3. 전체 데이터셋 생성 (2-3시간)
python scripts/generate_datasets.py generate_all

# 4. 개별 데이터셋 생성
python scripts/generate_datasets.py generate_volume_focused --multiplier=20
```

## 🔧 점진적 회전 훈련을 위한 데이터셋 증배기 수정사항

### 새로운 데이터셋 생성 방법

데이터셋 증배기는 도메인 갭 해결을 위해 점진적 증강 전략을 지원하도록 확장되었습니다:

#### K-Fold 교차검증 데이터셋 생성
```python
def generate_kfold_datasets(k=2, multiplier=10, strategy="phase1_mild"):
    """
    계층적 K-fold 데이터셋 생성
    
    Args:
        k: 폴드 수 (기본값: 2)
        multiplier: 증강 배수
        strategy: 증강 전략 ("phase1_mild", "phase2_variety", "phase3_full")
    """
```

#### 점진적 증강 전략
1. **Phase 1 (Mild)**: ±20° 회전, 경미한 조명 변화
2. **Phase 2 (Variety)**: ±60° 회전, 중간 조명 변화, 이산 90° 회전
3. **Phase 3 (Full)**: ±90° 회전, 전체 조명 변화, 플립 변환

### CLI 명령어 추가

```bash
# Phase 1: 경미한 회전 K-fold 데이터셋
python scripts/generate_datasets.py generate_kfold \
    --k=2 --multiplier=10 --strategy=phase1_mild

# Phase 2: 다양한 회전 K-fold 데이터셋  
python scripts/generate_datasets.py generate_kfold \
    --k=2 --multiplier=10 --strategy=phase2_variety

# Phase 3: 완전한 회전 K-fold 데이터셋
python scripts/generate_datasets.py generate_kfold \
    --k=2 --multiplier=15 --strategy=phase3_full

# 점진적 데이터셋 생성
python scripts/generate_datasets.py generate_progressive --multiplier=3

# 테스트 조건 중심 데이터셋 생성
python scripts/generate_datasets.py generate_test_focused --multiplier=1
```

### 체크포인트 로딩을 통한 점진적 훈련

```bash
# 점진적 훈련 파이프라인
python scripts/train.py experiment=phase1_rotation_mild
python scripts/train.py experiment=phase2_rotation_variety
python scripts/train.py experiment=phase3_rotation_full
```

**예상 출력**: 총 47,100개 샘플의 3개 데이터셋이 점진적 훈련 단계별로 준비됩니다.

## 📊 생성된 데이터셋 구조

```bash
data/augmented_datasets/
├── v1_volume_20x/          # 31,400 샘플 (다양성 중심)
├── v2_test_focused_10x/    # 15,700 샘플 (테스트 조건 시뮬레이션)
├── v3_balanced_15x/        # 23,550 샘플 (클래스 균형)
├── phase1_mild_fold_0/     # Phase 1 데이터셋
├── phase2_variety_fold_0/  # Phase 2 데이터셋
├── phase3_full_fold_0/     # Phase 3 데이터셋
└── generation_summary.json # 전체 생성 요약
```

## 🔧 주요 기능

### 메모리 효율적 처리
- **배치 처리**: 메모리 효율적 처리
- **진행률 추적**: tqdm + icecream 로깅
- **오류 처리**: 개별 이미지 실패시 건너뛰기
- **메타데이터 관리**: 각 데이터셋별 CSV 자동 생성
- **저장 최적화**: 배치 단위 저장

### 계층적 K-Fold 분할
- **데이터 누수 방지**: 소스 레벨 분할
- **클래스 균형 유지**: 계층적 분할 전략
- **교차 단계 검증**: 서로 다른 증강 단계 간 검증

### 도메인 적응 증강 전략
- **회전 적응**: 점진적 회전 각도 증가 (±20° → ±60° → ±90°)
- **조명 적응**: 테스트 조건에 맞는 조명 변화
- **노이즈 적응**: 임펄스에서 가우시안 노이즈로 전환

## 💾 순수 볼륨 데이터 생성기

### 기본 사용법
```bash
# Python 스크립트로 직접 실행
python -c "
from src.data.pure_volume_generator import PureVolumeGenerator
generator = PureVolumeGenerator()
dataset_path = generator.generate_pure_volume_dataset(multiplier=3)
print(f'데이터셋 생성 위치: {dataset_path}')
"
```

### 회전 없는 순수 볼륨 테스트
```bash
# 가설 검증을 위한 회전 없는 3배 데이터셋
python scripts/train.py experiment=pure_volume_3x_test
```

## 🖥️ 시스템 모니터링

### Linux 명령줄에서 CPU 사용량 확인
```bash
# 실시간 프로세스 모니터링
top

# CPU별 사용률 확인
mpstat -P ALL

# 평균 사용률 확인
iostat

# CPU 활용률 5초 간격 모니터링
sar -u 5

# 고급 시스템 모니터링 도구 설치 및 실행
sudo apt install nmon
nmon
```

## 📋 데이터셋 유형별 상세 설명

### 1. 볼륨 중심 데이터셋 (Volume-Focused)
```bash
python scripts/generate_datasets.py generate_volume_focused --multiplier=20
```
- **목적**: 데이터 부족 문제 해결
- **특징**: 클래스 균형 유지, 다양한 증강 기법 적용
- **권장 사용**: 기본 성능 향상, 과적합 방지

### 2. 테스트 조건 중심 데이터셋 (Test-Focused)
```bash
python scripts/generate_datasets.py generate_test_focused --multiplier=10
```
- **목적**: 테스트 데이터 조건 시뮬레이션
- **특징**: 회전, 조명, 노이즈 조건을 테스트 데이터와 유사하게 조정
- **권장 사용**: 도메인 갭 해결, 일반화 성능 향상

### 3. 균형 데이터셋 (Balanced)
```bash
python scripts/generate_datasets.py generate_balanced --multiplier=15
```
- **목적**: 클래스 불균형 해결
- **특징**: 소수 클래스에 더 많은 증강 적용
- **권장 사용**: 클래스별 성능 균형 개선

### 4. 점진적 데이터셋 (Progressive)
```bash
python scripts/generate_datasets.py generate_progressive --multiplier=5
```
- **목적**: 안전한 도메인 적응
- **특징**: 3단계 점진적 증강 강도 증가
- **권장 사용**: 기존 성능 유지하며 개선

## ⚡ 성능 최적화 팁

### 배치 크기 조정
```python
# 메모리 제한 환경
BATCH_SIZE = 32  # 기본값

# 고성능 환경
BATCH_SIZE = 64  # 빠른 처리
```

### 병렬 처리 설정
```python
# CPU 코어 수에 따른 워커 수 조정
NUM_WORKERS = min(8, os.cpu_count())
```

### 저장 공간 관리
```bash
# 저장 공간 확인
df -h

# 임시 파일 정리
python scripts/generate_datasets.py cleanup_temp_files
```

## 🔍 문제 해결 가이드

### 일반적인 오류와 해결방법

#### 1. 메모리 부족 오류
```bash
# 배치 크기 줄이기
python scripts/generate_datasets.py generate_volume_focused --multiplier=10 --batch_size=16
```

#### 2. 저장 공간 부족
```bash
# 저장 공간 확인 후 증강 배수 조정
python scripts/generate_datasets.py check_storage_space
python scripts/generate_datasets.py generate_volume_focused --multiplier=5
```

#### 3. 데이터 로딩 오류
```bash
# 손상된 이미지 파일 스킵 설정
python scripts/generate_datasets.py generate_volume_focused --skip_corrupted=True
```

## 📈 성능 벤치마크

### 생성 속도 비교
| 데이터셋 유형 | 샘플 수 | 예상 시간 | 저장 공간 |
|---------------|---------|----------|----------|
| Volume 10x | 15,700 | 45분 | 8GB |
| Test-Focused 10x | 15,700 | 50분 | 9GB |
| Progressive 5x | 23,550 | 75분 | 12GB |
| K-Fold 2x3 | 47,100 | 150분 | 25GB |

### 시스템 요구사항
- **최소 RAM**: 16GB
- **권장 RAM**: 32GB
- **저장 공간**: 50GB 이상 여유 공간
- **CPU**: 멀티코어 프로세서 권장

## 🎯 모범 사례

### 1. 데이터셋 생성 전 계획
- 저장 공간 확인
- 목표 성능 설정
- 증강 전략 선택

### 2. 점진적 접근
- 작은 배수로 시작 (2-3배)
- 성능 확인 후 확장
- 메모리 사용량 모니터링

### 3. 실험 추적
- 각 데이터셋별 성능 기록
- WandB로 실험 비교
- 최적 설정 문서화

## 🚀 향후 개선 계획

### 구현 예정 기능
- **자동 하이퍼파라미터 튜닝**: Optuna 연동
- **GAN 기반 증강**: 더 현실적인 데이터 생성
- **적응적 증강**: 성능에 따른 동적 조정
- **분산 처리**: 다중 GPU 지원

### 최적화 방향
- **메모리 효율성**: 스트리밍 처리 구현
- **속도 개선**: CUDA 가속 증강
- **품질 향상**: 품질 평가 지표 통합