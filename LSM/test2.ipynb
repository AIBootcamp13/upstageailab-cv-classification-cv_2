{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from augraphy import AugraphyPipeline,  VoronoiTessellation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import uuid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_transform  = A.VerticalFlip(p=0.5)\n",
    "transform = A.Compose([\n",
    "    A.ISONoise(color_shift=(0.01, 0.07), intensity=(0.3, 0.8), p=0.7),\n",
    "    A.ColorJitter(\n",
    "        brightness=0, contrast=0, saturation=0, # 다른 효과는 끄고\n",
    "        hue=0.5, # 색조(hue)만 최대치로 변경\n",
    "        p=0.7# 50% 확률로 적용\n",
    "        ),\n",
    "    A.GaussianBlur(blur_limit=(3,7), p=0.5),\n",
    "    A.Rotate(\n",
    "        limit=360, p=0.7,\n",
    "        border_mode=0, value=(255,255,255)  # 흰색으로 채움\n",
    "    ),\n",
    "])\n",
    "\n",
    "# augmentation sequence\n",
    "my_sequence = [\n",
    "    VoronoiTessellation(\n",
    "        num_cells_range=(2000,2000),\n",
    "        mult_range=(50,80),\n",
    "        noise_type=\"random\",\n",
    "        background_value=(100,150),\n",
    "        numba_jit=1,\n",
    "        p=0.7\n",
    "),\n",
    "]\n",
    "pipeline  = AugraphyPipeline(my_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(\n",
    "    df,\n",
    "    test_size=0.5,  # 5:5 비율로 설정\n",
    "    random_state=42,\n",
    "    # 열의 위치 대신 '이름'을 사용하여 stratify 지정 (더 안정적인 방법)\n",
    "    stratify=df['target'] if 'target' in df.columns else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 3399/3400 [23:52<00:00,  3.96it/s]"
     ]
    }
   ],
   "source": [
    "# augmented\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "alpha = 0.8\n",
    "fit_count = 200\n",
    "pbar = tqdm(total=train_data['target'].unique().__len__()*fit_count)\n",
    "os.makedirs('./data/train_augmented', exist_ok=True)\n",
    "train_augmented = []\n",
    "for target,group in train_data.groupby('target'):\n",
    "    count = 0\n",
    "    while count < fit_count:\n",
    "        for file_name in group['ID'].values:\n",
    "            if count >= fit_count:\n",
    "                continue\n",
    "            count += 1\n",
    "            image = cv2.imread('./data/train/'+file_name)\n",
    "            if np.random.rand() < 0.4:\n",
    "                random_file_name = np.random.choice(train_data['ID'].values)\n",
    "                sum_image = cv2.imread('./data/train/'+random_file_name)\n",
    "                sum_image = cv2.resize(sum_image, (image.shape[1], image.shape[0]))\n",
    "                sum_image = vertical_transform(image=sum_image)['image']\n",
    "                image = cv2.addWeighted(image, alpha, sum_image, 1 - alpha, 0)\n",
    "            pbar.update(1)\n",
    "            augmented_image = pipeline.augment(np.array(image))['output']\n",
    "            augmented_image = transform(image=augmented_image)['image']\n",
    "            train_augmented_file_name = f\"{uuid.uuid4()}.jpg\"\n",
    "            Image.fromarray(augmented_image).save(f\"./data/train_augmented/{train_augmented_file_name}\")\n",
    "            train_augmented.append({'ID':train_augmented_file_name,'target':target})\n",
    "pd.DataFrame(train_augmented).to_csv('./data/train_augmented.csv',index=False)\n",
    "            # print(type(augmented_image))\n",
    "            # f\"{uuid.uuid4()}.jpg\"\n",
    "            # plt.imshow(augmented_image)\n",
    "            # plt.axis(\"off\")\n",
    "            # plt.show()\n",
    "            # raise\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3400 [00:46<44:16:58, 46.90s/it]\n",
      "100%|██████████| 3400/3400 [22:57<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# augmented\n",
    "from pandas import DataFrame\n",
    "\n",
    "alpha = 0.8\n",
    "fit_count = 200\n",
    "pbar = tqdm(total=val_data['target'].unique().__len__()*fit_count)\n",
    "os.makedirs('./data/val_augmented', exist_ok=True)\n",
    "val_augmented = []\n",
    "for target,group in val_data.groupby('target'):\n",
    "    count = 0\n",
    "    while count < fit_count:\n",
    "        for file_name in group['ID'].values:\n",
    "            if count >= fit_count:\n",
    "                continue\n",
    "            count += 1\n",
    "            image = cv2.imread('./data/train/'+file_name)\n",
    "            if np.random.rand() < 0.4:\n",
    "                random_file_name = np.random.choice(val_data['ID'].values)\n",
    "                sum_image = cv2.imread('./data/train/'+random_file_name)\n",
    "                sum_image = cv2.resize(sum_image, (image.shape[1], image.shape[0]))\n",
    "                sum_image = vertical_transform(image=sum_image)['image']\n",
    "                image = cv2.addWeighted(image, alpha, sum_image, 1 - alpha, 0)\n",
    "            pbar.update(1)\n",
    "            augmented_image = pipeline.augment(np.array(image))['output']\n",
    "            augmented_image = transform(image=augmented_image)['image']\n",
    "            val_augmented_file_name = f\"{uuid.uuid4()}.jpg\"\n",
    "            Image.fromarray(augmented_image).save(f\"./data/val_augmented/{val_augmented_file_name}\")\n",
    "            val_augmented.append({'ID':val_augmented_file_name,'target':target})\n",
    "pd.DataFrame(val_augmented).to_csv('./data/val_augmented.csv',index=False)\n",
    "            # print(type(augmented_image))\n",
    "            # f\"{uuid.uuid4()}.jpg\"\n",
    "            # plt.imshow(augmented_image)\n",
    "            # plt.axis(\"off\")\n",
    "            # plt.show()\n",
    "            # raise\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
