{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from augraphy import AugraphyPipeline,  VoronoiTessellation\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_vertical_flip = A.VerticalFlip(p=0.5)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.GaussianBlur(blur_limit=(5,7), p=1.0),\n",
    "    A.Rotate(limit=360, p=1.0,border_mode=0, value=(255,255,255)),\n",
    "])\n",
    "my_sequence = [\n",
    "    VoronoiTessellation(\n",
    "        num_cells_range=(2000,2000),\n",
    "        mult_range=(50,80),\n",
    "        noise_type=\"random\",\n",
    "        background_value=(30,40),\n",
    "        numba_jit=1,\n",
    "        p=0.7\n",
    "    ),\n",
    "]\n",
    "pipeline  = AugraphyPipeline(my_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(\n",
    "    df,\n",
    "    test_size=0.5,  # 5:5 비율로 설정\n",
    "    random_state=42,\n",
    "    # 열의 위치 대신 '이름'을 사용하여 stratify 지정 (더 안정적인 방법)\n",
    "    stratify=df['target'] if 'target' in df.columns else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented\n",
    "\n",
    "\n",
    "alpha = 0.8\n",
    "fit_count = 500\n",
    "# path = './data/train_augmented2/'\n",
    "# save_path = './data/train_augmented2.csv'\n",
    "# data = train_data[:]\n",
    "\n",
    "path = './data/val_augmented2/'\n",
    "save_path = './data/val_augmented2.csv'\n",
    "data = val_data[:]\n",
    "\n",
    "pbar = tqdm(total=data['target'].unique().__len__()*fit_count)\n",
    "os.makedirs(path, exist_ok=True)\n",
    "data_augmented = []\n",
    "for target,group in data.groupby('target'):\n",
    "    count = 0\n",
    "    while fit_count > count:\n",
    "        for file_name in group['ID'].values:\n",
    "            if count >= fit_count:\n",
    "                continue\n",
    "            base = Image.open('./data/train/'+file_name).convert(\"RGBA\")\n",
    "\n",
    "            bw, bh = base.size\n",
    "            base = transform_to_vertical_flip(image=np.array(base))['image']\n",
    "            base = Image.fromarray(base)\n",
    "\n",
    "            if np.random.rand() < 0.2:\n",
    "                random_file_name = np.random.choice(data['ID'].values)\n",
    "                overlay = Image.open('./data/train/'+random_file_name).convert(\"RGBA\")\n",
    "                ow, oh = overlay.size\n",
    "                overlay = transform_to_vertical_flip(image=np.array(overlay))['image']\n",
    "                overlay = Image.fromarray(overlay)\n",
    "\n",
    "                # 1️⃣ overlay 이미지 비율 유지해서 축소\n",
    "                scale = min(bw / ow, bh / oh)\n",
    "                new_w = int(ow * scale)\n",
    "                new_h = int(oh * scale)\n",
    "                overlay_resized = overlay.resize((new_w, new_h), resample=Image.LANCZOS)\n",
    "\n",
    "                # 2️⃣ overlay 이미지 중앙 배치용 투명 캔버스\n",
    "                transparent_overlay = Image.new(\"RGBA\", (bw, bh), (0, 0, 0, 0))\n",
    "\n",
    "                # 중앙 배치\n",
    "                x_offset = (bw - new_w) // 2\n",
    "                y_offset = (bh - new_h) // 2\n",
    "                transparent_overlay.paste(overlay_resized, (x_offset, y_offset))\n",
    "\n",
    "                # 3️⃣ 투명도 적용 (선택)\n",
    "                alpha = 20  # 0~255\n",
    "                transparent_overlay.putalpha(alpha)\n",
    "\n",
    "                # 4️⃣ 합성\n",
    "                base = Image.alpha_composite(base, transparent_overlay)\n",
    "            base = base.convert(\"RGB\")\n",
    "            pbar.update(1)\n",
    "            base = pipeline.augment(np.array(base))['output']\n",
    "            augmented_image = transform(image=np.array(base))['image']\n",
    "            augmented_file_name = f\"{uuid.uuid4()}.jpg\"\n",
    "            Image.fromarray(augmented_image).save(f\"{path}{augmented_file_name}\")\n",
    "            data_augmented.append({'ID':augmented_file_name,'target':target})\n",
    "            count+=1\n",
    "pd.DataFrame(data_augmented).sample(frac=1).reset_index(drop=True).to_csv(save_path,index=False)\n",
    "pbar.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
