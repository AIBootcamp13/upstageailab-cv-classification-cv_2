{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 원본 데이터를 학습용과 검증용으로 분리합니다.\n",
      "분리 결과 -> 학습용: 785개, 검증용: 785개\n",
      "\n",
      "🚀 학습 데이터 증강 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습 데이터 증강:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습 데이터 증강: 100%|██████████| 24/24 [3:24:02<00:00, 510.11s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: 76800개의 증강 이미지가 './data/train_augmented_v2/images'에 저장되었습니다.\n",
      "\n",
      "🚀 검증 데이터 증강 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증 데이터 증강: 100%|██████████| 24/24 [3:24:09<00:00, 510.40s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: 76800개의 증강 이미지가 './data/val_augmented_v2/images'에 저장되었습니다.\n",
      "\n",
      "🎉 모든 작업이 완료되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "from timm.data.mixup import Mixup\n",
    "import albumentations as A\n",
    "from augraphy import AugraphyPipeline, VoronoiTessellation\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. 기본 설정\n",
    "# --------------------------------------------------------------------------\n",
    "# 원본 데이터 경로\n",
    "ORIGINAL_CSV_PATH = './data/train.csv'\n",
    "ORIGINAL_IMG_DIR = './data/train/'\n",
    "\n",
    "# 최종적으로 생성될 데이터 폴더 경로\n",
    "FINAL_TRAIN_DIR = './data/train_augmented_v2/'\n",
    "FINAL_VAL_DIR = './data/val_augmented_v2/'\n",
    "\n",
    "# 증강 및 분리 관련 파라미터\n",
    "VAL_SIZE = 0.5\n",
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 17\n",
    "AUGMENTATION_COUNT = 100 # 데이터셋 당 적용할 증강 횟수\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2. 데이터셋 클래스 및 초기 변환 (재사용)\n",
    "# --------------------------------------------------------------------------\n",
    "class ResizeWithPadding:\n",
    "    \"\"\"\n",
    "    이미지 비율을 유지하며 리사이즈하고, 남는 공간을 패딩으로 채웁니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, fill=(0, 0, 0)):\n",
    "        self.size = size\n",
    "        self.fill = fill\n",
    "\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        scale = min(self.size[0] / w, self.size[1] / h)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        resized = TF.resize(image, (new_h, new_w))\n",
    "        pad_left = (self.size[0] - new_w) // 2\n",
    "        pad_top = (self.size[1] - new_h) // 2\n",
    "        pad_right = self.size[0] - new_w - pad_left\n",
    "        pad_bottom = self.size[1] - new_h - pad_top\n",
    "        return TF.pad(resized, (pad_left, pad_top, pad_right, pad_bottom), fill=self.fill)\n",
    "\n",
    "initial_transform = T.Compose([\n",
    "ResizeWithPadding((591, 443), fill=(255, 255, 255)),\n",
    "T.ToTensor(),\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['ID']\n",
    "        label = self.df.iloc[idx]['target']\n",
    "        image_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 3. 핵심 기능 함수 (증강 및 저장 로직 통합)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def augment_and_save_dataset(df, base_dir, csv_name, description):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임에 증강을 적용하고 지정된 경로에 이미지와 CSV를 저장합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n🚀 {description} 시작...\")\n",
    "\n",
    "    # --- 경로 설정 및 폴더 생성 ---\n",
    "    output_img_dir = os.path.join(base_dir, 'images')\n",
    "    output_csv_path = os.path.join(base_dir, csv_name)\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "\n",
    "    # --- 증강 파이프라인 정의 ---\n",
    "    mixup_fn = Mixup(mixup_alpha=0.5, cutmix_alpha=0.0, prob=1.0, label_smoothing=0.1, num_classes=NUM_CLASSES)\n",
    "    augraphy_pipeline = AugraphyPipeline([\n",
    "    VoronoiTessellation(num_cells_range=(150, 250), p=0.5)\n",
    "    ])\n",
    "    albumentations_transform = A.Compose([\n",
    "    # A.GaussianBlur(blur_limit=(5, 7), p=1.0),\n",
    "    A.Rotate(limit=360, p=0.9, border_mode=0, value=(255, 255, 255)),\n",
    "    ])\n",
    "\n",
    "    # --- 데이터 로딩 및 증강 ---\n",
    "    dataset = CustomImageDataset(df=df, image_dir=ORIGINAL_IMG_DIR, transform=initial_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE,drop_last=True)\n",
    "\n",
    "    new_metadata = []\n",
    "    for images, labels in tqdm(dataloader, desc=description):\n",
    "        for _ in range(AUGMENTATION_COUNT):\n",
    "            if images.size(0) % 2 != 0:\n",
    "                images = torch.cat([images, images[-1].unsqueeze(0)], dim=0)\n",
    "                labels = torch.cat([labels, labels[-1].unsqueeze(0)], dim=0)\n",
    "            mixed_images, mixed_labels = mixup_fn(images, labels)\n",
    "            for i in range(mixed_images.size(0)):\n",
    "                img_tensor, label_array = mixed_images[i], mixed_labels[i].cpu().numpy()\n",
    "                img_np = np.array(TF.to_pil_image(img_tensor))\n",
    "\n",
    "                # Augraphy -> Albumentations 적용\n",
    "                augmented_np = albumentations_transform(image=augraphy_pipeline(image=img_np))[\"image\"]\n",
    "\n",
    "                final_image_pil = Image.fromarray(augmented_np)\n",
    "                filename = f\"{uuid.uuid4()}.png\"\n",
    "                final_image_pil.save(os.path.join(output_img_dir, filename))\n",
    "\n",
    "                new_metadata.append({'ID': filename, 'target': str(list(label_array))})\n",
    "\n",
    "    df_new = pd.DataFrame(new_metadata)\n",
    "    df_new.to_csv(output_csv_path, index=False)\n",
    "    print(f\"✅ 완료: {len(df_new)}개의 증강 이미지가 '{output_img_dir}'에 저장되었습니다.\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 4. 메인 실행 블록\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# --- 1. 데이터 분리 ---\n",
    "print(\"📊 원본 데이터를 학습용과 검증용으로 분리합니다.\")\n",
    "df_original = pd.read_csv(ORIGINAL_CSV_PATH)\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "df_original,\n",
    "test_size=VAL_SIZE,\n",
    "shuffle=True,\n",
    "random_state=RANDOM_STATE,\n",
    "stratify=df_original['target']\n",
    ")\n",
    "print(f\"분리 결과 -> 학습용: {len(df_train)}개, 검증용: {len(df_val)}개\")\n",
    "\n",
    "# --- 2. 학습 데이터 증강 및 저장 ---\n",
    "augment_and_save_dataset(\n",
    "    df=df_train,\n",
    "    base_dir=FINAL_TRAIN_DIR,\n",
    "    csv_name='train_augmented_v2.csv',\n",
    "    description=\"학습 데이터 증강\"\n",
    ")\n",
    "\n",
    "# --- 3. 검증 데이터 증강 및 저장 ---\n",
    "augment_and_save_dataset(\n",
    "    df=df_val,\n",
    "    base_dir=FINAL_VAL_DIR,\n",
    "    csv_name='val_augmented_v2.csv',\n",
    "    description=\"검증 데이터 증강\"\n",
    ")\n",
    "\n",
    "print(\"\\n🎉 모든 작업이 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 원본 데이터를 학습용과 검증용으로 분리합니다.\n",
      "분리 결과 -> 학습용: 785개, 검증용: 785개\n",
      "\n",
      "🚀 학습 데이터 증강 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습 데이터 증강:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "학습 데이터 증강: 100%|██████████| 24/24 [02:15<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: 768개의 증강 이미지가 './data/train_augmented_v2/images'에 저장되었습니다.\n",
      "\n",
      "🚀 검증 데이터 증강 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "검증 데이터 증강: 100%|██████████| 24/24 [02:12<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 완료: 768개의 증강 이미지가 './data/val_augmented_v2/images'에 저장되었습니다.\n",
      "\n",
      "🎉 모든 작업이 완료되었습니다!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "from timm.data.mixup import Mixup\n",
    "import albumentations as A\n",
    "from augraphy import AugraphyPipeline, VoronoiTessellation\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 1. 기본 설정\n",
    "# --------------------------------------------------------------------------\n",
    "# 원본 데이터 경로\n",
    "ORIGINAL_CSV_PATH = './data/train.csv'\n",
    "ORIGINAL_IMG_DIR = './data/train/'\n",
    "\n",
    "# 최종적으로 생성될 데이터 폴더 경로\n",
    "FINAL_TRAIN_DIR = './data/train_augmented_v2/'\n",
    "FINAL_VAL_DIR = './data/val_augmented_v2/'\n",
    "\n",
    "# 증강 및 분리 관련 파라미터\n",
    "VAL_SIZE = 0.5\n",
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 17\n",
    "AUGMENTATION_COUNT = 100 # 데이터셋 당 적용할 증강 횟수\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 2. 데이터셋 클래스 및 초기 변환 (재사용)\n",
    "# --------------------------------------------------------------------------\n",
    "class ResizeWithPadding:\n",
    "    \"\"\"\n",
    "    이미지 비율을 유지하며 리사이즈하고, 남는 공간을 패딩으로 채웁니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, fill=(0, 0, 0)):\n",
    "        self.size = size\n",
    "        self.fill = fill\n",
    "\n",
    "    def __call__(self, image):\n",
    "        w, h = image.size\n",
    "        scale = min(self.size[0] / w, self.size[1] / h)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        resized = TF.resize(image, (new_h, new_w))\n",
    "        pad_left = (self.size[0] - new_w) // 2\n",
    "        pad_top = (self.size[1] - new_h) // 2\n",
    "        pad_right = self.size[0] - new_w - pad_left\n",
    "        pad_bottom = self.size[1] - new_h - pad_top\n",
    "        return TF.pad(resized, (pad_left, pad_top, pad_right, pad_bottom), fill=self.fill)\n",
    "\n",
    "initial_transform = T.Compose([\n",
    "    ResizeWithPadding((591, 443), fill=(255, 255, 255)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['ID']\n",
    "        label = self.df.iloc[idx]['target']\n",
    "        image_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 3. 핵심 기능 함수 (증강 및 저장 로직 통합)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def augment_and_save_dataset(df, base_dir, csv_name, description):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임에 증강을 적용하고 지정된 경로에 이미지와 CSV를 저장합니다.\n",
    "    \"\"\"\n",
    "    print(f\"\\n🚀 {description} 시작...\")\n",
    "\n",
    "    # --- 경로 설정 및 폴더 생성 ---\n",
    "    output_img_dir = os.path.join(base_dir, 'images')\n",
    "    output_csv_path = os.path.join(base_dir, csv_name)\n",
    "    os.makedirs(output_img_dir, exist_ok=True)\n",
    "\n",
    "    # --- 증강 파이프라인 정의 ---\n",
    "    mixup_fn = Mixup(mixup_alpha=0.5, cutmix_alpha=0.0, prob=1.0, label_smoothing=0.1, num_classes=NUM_CLASSES)\n",
    "    augraphy_pipeline = AugraphyPipeline([\n",
    "        VoronoiTessellation(num_cells_range=(150, 250), p=0.5)\n",
    "    ])\n",
    "    albumentations_transform = A.Compose([\n",
    "        # A.GaussianBlur(blur_limit=(5, 7), p=1.0),\n",
    "        A.Rotate(limit=360, p=0.9, border_mode=0, value=(255, 255, 255)),\n",
    "    ])\n",
    "\n",
    "    # --- 데이터 로딩 및 증강 ---\n",
    "    dataset = CustomImageDataset(df=df, image_dir=ORIGINAL_IMG_DIR, transform=initial_transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZEArithmeticError)\n",
    "\n",
    "    new_metadata = []\n",
    "    for images, labels in tqdm(dataloader, desc=description):\n",
    "        for _ in range(AUGMENTATION_COUNT):\n",
    "            if images.size(0) % 2 != 0:\n",
    "                # 마지막 이미지와 라벨을 복제하여 이어 붙임\n",
    "                images = torch.cat([images, images[-1].unsqueeze(0)], dim=0)\n",
    "                labels = torch.cat([labels, labels[-1].unsqueeze(0)], dim=0)\n",
    "            mixed_images, mixed_labels = mixup_fn(images, labels)\n",
    "            for i in range(mixed_images.size(0)):\n",
    "                img_tensor, label_array = mixed_images[i], mixed_labels[i].cpu().numpy()\n",
    "                img_np = np.array(TF.to_pil_image(img_tensor))\n",
    "\n",
    "                # Augraphy -> Albumentations 적용\n",
    "                augmented_np = albumentations_transform(image=augraphy_pipeline(image=img_np))[\"image\"]\n",
    "\n",
    "                final_image_pil = Image.fromarray(augmented_np)\n",
    "                filename = f\"{uuid.uuid4()}.png\"\n",
    "                final_image_pil.save(os.path.join(output_img_dir, filename))\n",
    "\n",
    "                new_metadata.append({'ID': filename, 'target': str(list(label_array))})\n",
    "\n",
    "    df_new = pd.DataFrame(new_metadata)\n",
    "    df_new.to_csv(output_csv_path, index=False)\n",
    "    print(f\"✅ 완료: {len(df_new)}개의 증강 이미지가 '{output_img_dir}'에 저장되었습니다.\")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 4. 메인 실행 블록\n",
    "# --------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    # --- 1. 데이터 분리 ---\n",
    "    print(\"📊 원본 데이터를 학습용과 검증용으로 분리합니다.\")\n",
    "    df_original = pd.read_csv(ORIGINAL_CSV_PATH)\n",
    "\n",
    "    df_train, df_val = train_test_split(\n",
    "        df_original,\n",
    "        test_size=VAL_SIZE,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=df_original['target']\n",
    "    )\n",
    "    print(f\"분리 결과 -> 학습용: {len(df_train)}개, 검증용: {len(df_val)}개\")\n",
    "\n",
    "    # --- 2. 학습 데이터 증강 및 저장 ---\n",
    "    augment_and_save_dataset(\n",
    "        df=df_train,\n",
    "        base_dir=FINAL_TRAIN_DIR,\n",
    "        csv_name='train_augmented_v2.csv',\n",
    "        description=\"학습 데이터 증강\"\n",
    "    )\n",
    "\n",
    "    # --- 3. 검증 데이터 증강 및 저장 ---\n",
    "    augment_and_save_dataset(\n",
    "        df=df_val,\n",
    "        base_dir=FINAL_VAL_DIR,\n",
    "        csv_name='val_augmented_v2.csv',\n",
    "        description=\"검증 데이터 증강\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n🎉 모든 작업이 완료되었습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= pd.read_csv('./data/train_augmented_v2/train_augmented_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c\n",
       "16    50\n",
       "10    50\n",
       "8     50\n",
       "11    50\n",
       "7     49\n",
       "15    49\n",
       "2     49\n",
       "3     49\n",
       "9     49\n",
       "4     49\n",
       "12    48\n",
       "6     47\n",
       "5     47\n",
       "0     47\n",
       "13    37\n",
       "14    25\n",
       "1     23\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "a = pd.read_csv('data/train_augmented_v2/train_augmented_v2.csv')\n",
    "a['target'] = a['target'].apply(lambda x : ast.literal_eval(x))\n",
    "a['c'] = a['target'].apply(lambda x : x.index(max(x)))\n",
    "a['c'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
