_wandb:
    value:
        cli_version: 0.20.1
        m:
            - "1": trainer/global_step
              "6":
                - 3
              "7": []
            - "1": lr-AdamW
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": train_loss_step
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": epoch
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": train_loss_epoch
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": train_acc
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": val_loss
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": val_acc
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": val_f1
              "5": 1
              "6":
                - 1
                - 3
              "7": []
            - "1": train_f1
              "5": 1
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.10.13
        t:
            "1":
                - 1
                - 5
                - 9
                - 41
                - 49
                - 50
                - 53
                - 63
                - 80
                - 103
            "2":
                - 1
                - 5
                - 9
                - 41
                - 49
                - 50
                - 53
                - 63
                - 80
                - 103
            "3":
                - 2
                - 7
                - 13
                - 15
                - 16
                - 55
                - 66
            "4": 3.10.13
            "5": 0.20.1
            "12": 0.20.1
            "13": linux-x86_64
config:
    dataset:
        name: augmented
        train_csv: data/train_augmented(base+1+2).csv
        train_img_dir: data/train_augmented(base+1+2)
        val_csv: data/val_augmented(base+1+2).csv
        val_img_dir: data/val_augmented(base+1+2)
    experiment:
        dataset: augmented
        description: 팀원1 실험 - efficientnet-b4 + cosine + 증강 데이터
        loss: cross_entropy
        model: efficientnet-b1
        name: lsm_efficientnet-b4_size_224_batch_32_adamw_augmented_v3+base
        optimizer: cosine
        scheduler: exponential
        tags:
            - team1
            - efficientnet-b4"
            - cosine
        transform: augmented
    logging:
        log_every_n_steps: 50
        project_name: document-classification
        save_top_k: 3
    loss:
        label_smoothing: 0
        name: cross_entropy
    model:
        dropout_rate: 0.5
        model_name: efficientnet-b4
        name: efficientnet
        num_classes: 17
        pretrained: true
    num_classes: 17
    optimizer:
        lr: 0.001
        name: adamw
        weight_decay: 0.0001
    s3:
        bucket_name: ""
        enabled: false
        region_name: us-east-1
    save:
        checkpoint_dir: checkpoints
        model_dir: experiments
    scheduler:
        _target_: src.schedulers.cosine.CosineScheduler
        T_max: 100
        eta_min: 0
        name: cosine
        params:
            T_max: 100
    seed: 42
    training:
        batch_size: 32
        max_epochs: 100
        num_workers: 4
        patience: 30
    transform:
        image_size: 224
        name: augmented
dataset:
    name: augmented
    train_csv: data/train_augmented(base+1+2).csv
    train_img_dir: data/train_augmented(base+1+2)
    val_csv: data/val_augmented(base+1+2).csv
    val_img_dir: data/val_augmented(base+1+2)
experiment:
    dataset: augmented
    description: 팀원1 실험 - efficientnet-b4 + cosine + 증강 데이터
    loss: cross_entropy
    model: efficientnet-b1
    name: lsm_efficientnet-b4_size_224_batch_32_adamw_augmented_v3+base
    optimizer: cosine
    scheduler: exponential
    tags:
        - team1
        - efficientnet-b4"
        - cosine
    transform: augmented
logging:
    log_every_n_steps: 50
    project_name: document-classification
    save_top_k: 3
loss:
    label_smoothing: 0
    name: cross_entropy
model:
    dropout_rate: 0.5
    model_name: efficientnet-b4
    name: efficientnet
    num_classes: 17
    pretrained: true
num_classes: 17
optimizer:
    lr: 0.001
    name: adamw
    weight_decay: 0.0001
s3:
    bucket_name: ""
    enabled: false
    region_name: us-east-1
save:
    checkpoint_dir: checkpoints
    model_dir: experiments
scheduler:
    _target_: src.schedulers.cosine.CosineScheduler
    T_max: 100
    eta_min: 0
    name: cosine
    params:
        T_max: 100
seed: 42
training:
    batch_size: 32
    max_epochs: 100
    num_workers: 4
    patience: 30
transform:
    image_size: 224
    name: augmented
