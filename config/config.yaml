# 기본 설정
seed: 42
device: 'cuda' # 'cuda' 또는 'cpu'

# 데이터 설정
data:
  root_dir: "data/dataset"
  image_size: 224
  val_size: 0.2
  num_workers: 4
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  use_document_augmentation: False

  # 추가: 데이터 증강 설정
  augmentations:
    use_blur: true
    blur_params:
      blur_limit: [3, 7]  # 최소값을 3으로 설정
      sigma_limit: [0.1, 2.0]  # 최소값을 0보다 크게 설정
      
# 모델 설정
model:
  name: "resnet50" # timm 라이브러리에서 지원하는 모델명
  pretrained: true

# 학습 설정
train:
  epochs: 20
  batch_size: 32
  optimizer: 'AdamW' # 'Adam', 'AdamW', 'SGD' 등 torch.optim에 있는 옵티마이저
  loss: 'CrossEntropyLoss' # 'CrossEntropyLoss', 'FocalLoss' 등 (FocalLoss는 별도 구현 필요)

  # 옵티마이저 하이퍼파라미터
  learning_rate: 0.0001
  weight_decay: 0.0001

  # 스케줄러 설정 (비어있으면 사용 안 함)
  scheduler: 'CosineAnnealingLR' # 'CosineAnnealingLR', 'ReduceLROnPlateau' 등
  scheduler_params:
    T_max: 20 # for CosineAnnealingLR
    eta_min: 0.000001 # for CosineAnnealingLR
    # mode: 'min' # for ReduceLROnPlateau
    # factor: 0.1 # for ReduceLROnPlateau
    # patience: 3 # for ReduceLROnPlateau

  # 조기 종료 설정 (train 섹션 안으로 이동)
  early_stopping:
    patience: 5
    metric: 'val_f1' # 'val_loss', 'val_acc', 'val_f1'
    mode: 'max' # val_loss의 경우 'min', 나머지는 'max'

# 로깅 및 저장 경로
logging:
  log_dir: "logs"
  checkpoint_dir: "checkpoints"
  log_interval: 10 # N 배치마다 학습 손실 로그 출력